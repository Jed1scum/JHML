{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our Neural Net with 3 layers. Change path depending on where the script is located\n",
    "exec(open(\"../Utilities/NNx3.py\").read())\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Cultivar 1</th>\n",
       "      <th>Cultivar 2</th>\n",
       "      <th>Cultivar 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.246290</td>\n",
       "      <td>-0.499413</td>\n",
       "      <td>-0.827996</td>\n",
       "      <td>-2.490847</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.568648</td>\n",
       "      <td>0.733629</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>-0.544721</td>\n",
       "      <td>-0.293321</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>1.113449</td>\n",
       "      <td>0.965242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.691550</td>\n",
       "      <td>-0.346811</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>-0.809251</td>\n",
       "      <td>0.930918</td>\n",
       "      <td>2.491446</td>\n",
       "      <td>1.466525</td>\n",
       "      <td>-0.981875</td>\n",
       "      <td>1.032155</td>\n",
       "      <td>1.186068</td>\n",
       "      <td>-0.427544</td>\n",
       "      <td>1.184071</td>\n",
       "      <td>2.334574</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.227694</td>\n",
       "      <td>1.840403</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>1.281985</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>0.663351</td>\n",
       "      <td>0.226796</td>\n",
       "      <td>0.401404</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>0.449601</td>\n",
       "      <td>-0.037874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.481555</td>\n",
       "      <td>-0.517367</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>-1.289707</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>1.562093</td>\n",
       "      <td>1.366128</td>\n",
       "      <td>-0.176095</td>\n",
       "      <td>0.664217</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>0.336606</td>\n",
       "      <td>2.239039</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.716255</td>\n",
       "      <td>-0.418624</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>-1.469878</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>0.328298</td>\n",
       "      <td>0.492677</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>1.367689</td>\n",
       "      <td>1.729520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Alcohol  Malic acid       Ash  Alcalinity of ash  Magnesium  \\\n",
       "0  0.246290   -0.499413 -0.827996          -2.490847   0.018145   \n",
       "1  1.691550   -0.346811  0.487926          -0.809251   0.930918   \n",
       "2  0.295700    0.227694  1.840403           0.451946   1.281985   \n",
       "3  1.481555   -0.517367  0.305159          -1.289707   0.860705   \n",
       "4  1.716255   -0.418624  0.305159          -1.469878  -0.262708   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0       0.568648    0.733629             -0.820719        -0.544721   \n",
       "1       2.491446    1.466525             -0.981875         1.032155   \n",
       "2       0.808997    0.663351              0.226796         0.401404   \n",
       "3       1.562093    1.366128             -0.176095         0.664217   \n",
       "4       0.328298    0.492677             -0.498407         0.681738   \n",
       "\n",
       "   Color intensity       Hue  OD280/OD315 of diluted wines   Proline  \\\n",
       "0        -0.293321  0.406051                      1.113449  0.965242   \n",
       "1         1.186068 -0.427544                      1.184071  2.334574   \n",
       "2        -0.319276  0.362177                      0.449601 -0.037874   \n",
       "3         0.731870  0.406051                      0.336606  2.239039   \n",
       "4         0.083015  0.274431                      1.367689  1.729520   \n",
       "\n",
       "   Cultivar 1  Cultivar 2  Cultivar 3  \n",
       "0           1           0           0  \n",
       "1           1           0           0  \n",
       "2           1           0           0  \n",
       "3           1           0           0  \n",
       "4           1           0           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('W1data.csv')\n",
    "dfTest = pd.read_csv('W1TestData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "y = df[['Cultivar 1', 'Cultivar 2', 'Cultivar 3']].values\n",
    "\n",
    "# Get inputs; we define our x and y here.\n",
    "X = df.drop(['Cultivar 1', 'Cultivar 2', 'Cultivar 3'], axis = 1)\n",
    "X.shape, y.shape # Print shapes just to check\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 1.4619703912286877\n",
      "Accuracy after iteration 0 : 24.539877300613497 %\n",
      "Loss after iteration 100 : 0.5410202294391878\n",
      "Accuracy after iteration 100 : 79.75460122699386 %\n",
      "Loss after iteration 200 : 0.4080293260109097\n",
      "Accuracy after iteration 200 : 85.88957055214725 %\n",
      "Loss after iteration 300 : 0.35777911648501554\n",
      "Accuracy after iteration 300 : 87.73006134969326 %\n",
      "Loss after iteration 400 : 0.3309813130264834\n",
      "Accuracy after iteration 400 : 88.95705521472392 %\n",
      "Loss after iteration 500 : 0.31100773668997195\n",
      "Accuracy after iteration 500 : 88.95705521472392 %\n",
      "Loss after iteration 600 : 0.29279721209183823\n",
      "Accuracy after iteration 600 : 88.95705521472392 %\n",
      "Loss after iteration 700 : 0.27377332699561086\n",
      "Accuracy after iteration 700 : 88.95705521472392 %\n",
      "Loss after iteration 800 : 0.26020299559480736\n",
      "Accuracy after iteration 800 : 88.95705521472392 %\n",
      "Loss after iteration 900 : 0.2451752446736815\n",
      "Accuracy after iteration 900 : 88.95705521472392 %\n",
      "Loss after iteration 1000 : 0.23328634720806354\n",
      "Accuracy after iteration 1000 : 91.41104294478528 %\n",
      "Loss after iteration 1100 : 0.22387338114330593\n",
      "Accuracy after iteration 1100 : 92.02453987730061 %\n",
      "Loss after iteration 1200 : 0.20024678639973392\n",
      "Accuracy after iteration 1200 : 92.02453987730061 %\n",
      "Loss after iteration 1300 : 0.18741428035754282\n",
      "Accuracy after iteration 1300 : 92.63803680981594 %\n",
      "Loss after iteration 1400 : 0.17602379298318693\n",
      "Accuracy after iteration 1400 : 93.25153374233128 %\n",
      "Loss after iteration 1500 : 0.16567932515430203\n",
      "Accuracy after iteration 1500 : 93.86503067484662 %\n",
      "Loss after iteration 1600 : 0.15773723847206594\n",
      "Accuracy after iteration 1600 : 94.47852760736197 %\n",
      "Loss after iteration 1700 : 0.15298508918378761\n",
      "Accuracy after iteration 1700 : 94.47852760736197 %\n",
      "Loss after iteration 1800 : 0.1496036648962879\n",
      "Accuracy after iteration 1800 : 94.47852760736197 %\n",
      "Loss after iteration 1900 : 0.14690541626691983\n",
      "Accuracy after iteration 1900 : 94.47852760736197 %\n",
      "Loss after iteration 2000 : 0.14466711126872134\n",
      "Accuracy after iteration 2000 : 94.47852760736197 %\n",
      "Loss after iteration 2100 : 0.14274632609613921\n",
      "Accuracy after iteration 2100 : 94.47852760736197 %\n",
      "Loss after iteration 2200 : 0.14105478988307757\n",
      "Accuracy after iteration 2200 : 94.47852760736197 %\n",
      "Loss after iteration 2300 : 0.139538837147013\n",
      "Accuracy after iteration 2300 : 94.47852760736197 %\n",
      "Loss after iteration 2400 : 0.1381590536089957\n",
      "Accuracy after iteration 2400 : 94.47852760736197 %\n",
      "Loss after iteration 2500 : 0.13688041530549844\n",
      "Accuracy after iteration 2500 : 94.47852760736197 %\n",
      "Loss after iteration 2600 : 0.13566256655753042\n",
      "Accuracy after iteration 2600 : 94.47852760736197 %\n",
      "Loss after iteration 2700 : 0.1344357411388349\n",
      "Accuracy after iteration 2700 : 94.47852760736197 %\n",
      "Loss after iteration 2800 : 0.1329813513262281\n",
      "Accuracy after iteration 2800 : 94.47852760736197 %\n",
      "Loss after iteration 2900 : 0.12962412680703445\n",
      "Accuracy after iteration 2900 : 94.47852760736197 %\n",
      "Loss after iteration 3000 : 0.12410879960302691\n",
      "Accuracy after iteration 3000 : 95.0920245398773 %\n",
      "Loss after iteration 3100 : 0.1215630993417392\n",
      "Accuracy after iteration 3100 : 95.0920245398773 %\n",
      "Loss after iteration 3200 : 0.11863561826902874\n",
      "Accuracy after iteration 3200 : 95.70552147239265 %\n",
      "Loss after iteration 3300 : 0.11463650516964635\n",
      "Accuracy after iteration 3300 : 96.31901840490798 %\n",
      "Loss after iteration 3400 : 0.1127888361105384\n",
      "Accuracy after iteration 3400 : 96.31901840490798 %\n",
      "Loss after iteration 3500 : 0.11146549404821418\n",
      "Accuracy after iteration 3500 : 96.31901840490798 %\n",
      "Loss after iteration 3600 : 0.11035854626516534\n",
      "Accuracy after iteration 3600 : 96.31901840490798 %\n",
      "Loss after iteration 3700 : 0.10934417606445253\n",
      "Accuracy after iteration 3700 : 96.31901840490798 %\n",
      "Loss after iteration 3800 : 0.10834087629699816\n",
      "Accuracy after iteration 3800 : 96.31901840490798 %\n",
      "Loss after iteration 3900 : 0.10724380811746845\n",
      "Accuracy after iteration 3900 : 96.31901840490798 %\n",
      "Loss after iteration 4000 : 0.10580252083347381\n",
      "Accuracy after iteration 4000 : 96.31901840490798 %\n",
      "Loss after iteration 4100 : 0.10296056666845388\n",
      "Accuracy after iteration 4100 : 96.31901840490798 %\n",
      "Loss after iteration 4200 : 0.08980522637673993\n",
      "Accuracy after iteration 4200 : 96.93251533742331 %\n",
      "Loss after iteration 4300 : 0.06712672950627403\n",
      "Accuracy after iteration 4300 : 98.15950920245399 %\n",
      "Loss after iteration 4400 : 0.06540956728635056\n",
      "Accuracy after iteration 4400 : 98.15950920245399 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28ef0b08278>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#need to make random start from a base of 0\n",
    "np.random.seed(0)\n",
    "#epochs is one full training forward and back propagation\n",
    "#LEarning rate is hoow rapidly the parameters change\n",
    "# This is what we return at the end\n",
    "model = initialise_parameters(nn_input_dim=13, nn_hdim= 5, nn_output_dim= 3)\n",
    "model = train(model,X,y,learning_rate=0.07,epochs=4500,print_loss=True)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "yTest = dfTest[['Cultivar 1', 'Cultivar 2', 'Cultivar 3']].values\n",
    "\n",
    "# Get inputs; we define our x and y here.\n",
    "XTest = dfTest.drop(['Cultivar 1', 'Cultivar 2', 'Cultivar 3'], axis = 1)\n",
    "XTest.shape, yTest.shape # Print shapes just to check\n",
    "XTest = XTest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now test on our test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest = predict(model,XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the test answers data array into a 1d array that can be compared for measuring the accuracy\n",
    "answersArray = []\n",
    "for index, row in dfTest[['Cultivar 1', 'Cultivar 2', 'Cultivar 3']].iterrows():\n",
    "    #print(str(index) +\" : \"+str((row.values)))\n",
    "    finalValue = 0;\n",
    "    for idx, num in enumerate(row.values):\n",
    "        correctedNum = idx*num\n",
    "        finalValue += correctedNum\n",
    "    answersArray.append(finalValue)\n",
    "    #print(str(index) +\":\" +str(finalValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 1, 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The predicted answers\n",
    "yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 1, 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the real answers\n",
    "np.array(answersArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#runn an accuracy score between the predicted numbers and real answers.\n",
    "accuracy_score(answersArray, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
