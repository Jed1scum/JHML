{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our Neural Net with 3 layers. Change path depending on where the script is located\n",
    "exec(open(\"../Utilities/NNx3.py\").read())\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                    34   0.9978  3.51       0.56   \n",
       "1                 25.0                    67   0.9968  3.20       0.68   \n",
       "2                 15.0                    54   0.9970  3.26       0.65   \n",
       "3                 17.0                    60   0.9980  3.16       0.58   \n",
       "4                 11.0                    34   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality_red_Train.csv')\n",
    "dfTest = pd.read_csv('winequality_red_Test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the data is clean of null values. if we see 0 then we are good\n",
    "df.isnull().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bad'] = 0\n",
    "df['average'] = 0\n",
    "df['good'] = 0\n",
    "#for each row, if quality is between range, then bad, average good = this thing\n",
    "for idx, row in enumerate(df['quality']):\n",
    "    if(row < 5):\n",
    "        df.loc[idx,'bad'] = 1\n",
    "    elif(row >6):\n",
    "        df.loc[idx,'good'] = 1\n",
    "    else:\n",
    "        df.loc[idx,'average'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "y = df[['bad','average','good']].values\n",
    "\n",
    "\n",
    "\n",
    "# Get inputs; we define our x and y here.\n",
    "X = df.drop(['quality', 'bad','average','good'], axis = 1)\n",
    "\n",
    "X.shape, y.shape # Print shapes just to check\n",
    "X = X.values\n",
    "\n",
    "inputDimensions = 11\n",
    "hiddenDimensions = 5\n",
    "outputDimensions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to make random start from a base of 0\n",
    "np.random.seed(0)\n",
    "#epochs is one full training forward and back propagation\n",
    "#LEarning rate is hoow rapidly the parameters change\n",
    "# This is what we return at the end\n",
    "model = initialise_parameters(nn_input_dim=inputDimensions, nn_hdim= hiddenDimensions, nn_output_dim= outputDimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0 : 0.8174295456322679\n",
      "Accuracy after iteration 0 : 82.32154769846565 %\n",
      "Loss after iteration 100 : 0.5571094768497864\n",
      "Accuracy after iteration 100 : 82.32154769846565 %\n",
      "Loss after iteration 200 : 0.55672012824998\n",
      "Accuracy after iteration 200 : 82.32154769846565 %\n",
      "Loss after iteration 300 : 0.5567066241319443\n",
      "Accuracy after iteration 300 : 82.32154769846565 %\n",
      "Loss after iteration 400 : 0.5567035088221697\n",
      "Accuracy after iteration 400 : 82.32154769846565 %\n",
      "Loss after iteration 500 : 0.5567020425454232\n",
      "Accuracy after iteration 500 : 82.32154769846565 %\n",
      "Loss after iteration 600 : 0.5567013247251897\n",
      "Accuracy after iteration 600 : 82.32154769846565 %\n",
      "Loss after iteration 700 : 0.5567009656370087\n",
      "Accuracy after iteration 700 : 82.32154769846565 %\n",
      "Loss after iteration 800 : 0.5567007692229653\n",
      "Accuracy after iteration 800 : 82.32154769846565 %\n",
      "Loss after iteration 900 : 0.556700643024791\n",
      "Accuracy after iteration 900 : 82.32154769846565 %\n",
      "Loss after iteration 1000 : 0.5567005461826269\n",
      "Accuracy after iteration 1000 : 82.32154769846565 %\n",
      "Loss after iteration 1100 : 0.5567004614395752\n",
      "Accuracy after iteration 1100 : 82.32154769846565 %\n",
      "Loss after iteration 1200 : 0.5567003817129862\n",
      "Accuracy after iteration 1200 : 82.32154769846565 %\n",
      "Loss after iteration 1300 : 0.5567003041452449\n",
      "Accuracy after iteration 1300 : 82.32154769846565 %\n",
      "Loss after iteration 1400 : 0.5567002275938306\n",
      "Accuracy after iteration 1400 : 82.32154769846565 %\n",
      "Loss after iteration 1500 : 0.5567001516029871\n",
      "Accuracy after iteration 1500 : 82.32154769846565 %\n",
      "Loss after iteration 1600 : 0.5567000759897497\n",
      "Accuracy after iteration 1600 : 82.32154769846565 %\n",
      "Loss after iteration 1700 : 0.556700000679039\n",
      "Accuracy after iteration 1700 : 82.32154769846565 %\n",
      "Loss after iteration 1800 : 0.5566999256383846\n",
      "Accuracy after iteration 1800 : 82.32154769846565 %\n",
      "Loss after iteration 1900 : 0.5566998508521788\n",
      "Accuracy after iteration 1900 : 82.32154769846565 %\n",
      "Loss after iteration 2000 : 0.5566997763115435\n",
      "Accuracy after iteration 2000 : 82.32154769846565 %\n",
      "Loss after iteration 2100 : 0.5566997020103415\n",
      "Accuracy after iteration 2100 : 82.32154769846565 %\n",
      "Loss after iteration 2200 : 0.5566996279436068\n",
      "Accuracy after iteration 2200 : 82.32154769846565 %\n",
      "Loss after iteration 2300 : 0.5566995541069244\n",
      "Accuracy after iteration 2300 : 82.32154769846565 %\n",
      "Loss after iteration 2400 : 0.5566994804961813\n",
      "Accuracy after iteration 2400 : 82.32154769846565 %\n",
      "Loss after iteration 2500 : 0.5566994071074662\n",
      "Accuracy after iteration 2500 : 82.32154769846565 %\n",
      "Loss after iteration 2600 : 0.5566993339370269\n",
      "Accuracy after iteration 2600 : 82.32154769846565 %\n",
      "Loss after iteration 2700 : 0.556699260981248\n",
      "Accuracy after iteration 2700 : 82.32154769846565 %\n",
      "Loss after iteration 2800 : 0.5566991882366418\n",
      "Accuracy after iteration 2800 : 82.32154769846565 %\n",
      "Loss after iteration 2900 : 0.5566991156998382\n",
      "Accuracy after iteration 2900 : 82.32154769846565 %\n",
      "Loss after iteration 3000 : 0.5566990433675815\n",
      "Accuracy after iteration 3000 : 82.32154769846565 %\n",
      "Loss after iteration 3100 : 0.556698971236724\n",
      "Accuracy after iteration 3100 : 82.32154769846565 %\n",
      "Loss after iteration 3200 : 0.5566988993042203\n",
      "Accuracy after iteration 3200 : 82.32154769846565 %\n",
      "Loss after iteration 3300 : 0.5566988275671252\n",
      "Accuracy after iteration 3300 : 82.32154769846565 %\n",
      "Loss after iteration 3400 : 0.5566987560225886\n",
      "Accuracy after iteration 3400 : 82.32154769846565 %\n",
      "Loss after iteration 3500 : 0.5566986846678509\n",
      "Accuracy after iteration 3500 : 82.32154769846565 %\n",
      "Loss after iteration 3600 : 0.5566986135002403\n",
      "Accuracy after iteration 3600 : 82.32154769846565 %\n",
      "Loss after iteration 3700 : 0.5566985425171687\n",
      "Accuracy after iteration 3700 : 82.32154769846565 %\n",
      "Loss after iteration 3800 : 0.556698471716129\n",
      "Accuracy after iteration 3800 : 82.32154769846565 %\n",
      "Loss after iteration 3900 : 0.5566984010946914\n",
      "Accuracy after iteration 3900 : 82.32154769846565 %\n",
      "Loss after iteration 4000 : 0.5566983306505003\n",
      "Accuracy after iteration 4000 : 82.32154769846565 %\n",
      "Loss after iteration 4100 : 0.556698260381272\n",
      "Accuracy after iteration 4100 : 82.32154769846565 %\n",
      "Loss after iteration 4200 : 0.556698190284791\n",
      "Accuracy after iteration 4200 : 82.32154769846565 %\n",
      "Loss after iteration 4300 : 0.5566981203589083\n",
      "Accuracy after iteration 4300 : 82.32154769846565 %\n",
      "Loss after iteration 4400 : 0.5566980506015385\n",
      "Accuracy after iteration 4400 : 82.32154769846565 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x255616b2320>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(model,X,y,learning_rate=0.07,epochs=4500,print_loss=True)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest['bad'] = 0\n",
    "dfTest['average'] = 0\n",
    "dfTest['good'] = 0\n",
    "#for each row, if quality is between range, then bad, average good = this thing\n",
    "for idx, row in enumerate(dfTest['quality']):\n",
    "    if(row < 5):\n",
    "        dfTest.loc[idx,'bad'] = 1\n",
    "    elif(row >6):\n",
    "        dfTest.loc[idx,'good'] = 1\n",
    "    else:\n",
    "        dfTest.loc[idx,'average'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "yTest = dfTest[['bad','average','good']].values\n",
    "\n",
    "# Get inputs; we define our x and y here.\n",
    "XTest = dfTest.drop(['bad','average','good'], axis = 1)\n",
    "XTest.shape, yTest.shape # Print shapes just to check\n",
    "XTest = XTest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest = predict(model,XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the test answers data array into a 1d array that can be compared for measuring the accuracy\n",
    "answersArray = []\n",
    "for index, row in dfTest[['bad','average','good']].iterrows():\n",
    "    #print(str(index) +\" : \"+str((row.values)))\n",
    "    finalValue = 0;\n",
    "    for idx, num in enumerate(row.values):\n",
    "        correctedNum = idx*num\n",
    "        finalValue += correctedNum\n",
    "    answersArray.append(finalValue)\n",
    "    #print(str(index) +\":\" +str(finalValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The predicted answers\n",
    "yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the real answers\n",
    "np.array(answersArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#runn an accuracy score between the predicted numbers and real answers.\n",
    "accuracy_score(answersArray, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
